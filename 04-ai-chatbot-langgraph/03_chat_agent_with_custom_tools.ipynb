{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6f6814",
   "metadata": {},
   "source": [
    "# Creating the AI Agent with some custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2285045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.tools import Tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from dotenv import load_dotenv\n",
    "import os, requests\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83165965",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ce8a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76507e6",
   "metadata": {},
   "source": [
    "## custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffd9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_tool_func(input: str) -> str:\n",
    "    greeting_prompt = (\n",
    "        f\"Generate a friendly greeting for {input}. Keep it short and cheerful.\"\n",
    "    )\n",
    "    greeting_response = llm.invoke(greeting_prompt).content\n",
    "    return greeting_response\n",
    "\n",
    "\n",
    "hello_tool = Tool(\n",
    "    name=\"hello_tool\",\n",
    "    func=hello_tool_func,\n",
    "    description=\"A tool that greets the user with a hello message.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8d822e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user_details(input: str) -> str:\n",
    "    users = requests.get(\"https://jsonplaceholder.typicode.com/users\").json()\n",
    "    for user in users:\n",
    "        if user[\"name\"].lower() in input.lower():\n",
    "            user_describe_prompt = f\"Describe the user with details {user['name']}, Email: {user['email']}, Lives in {user['address']['city']} at {user['address']['suite']}. He works in {user['company']['name']}. Tell as if you are giving a brief introduction about the user. For example say the user name is ABC with email XYZ, lives in the city EFG and works in the company HIJ. Keep it short and concise.\"\n",
    "            return llm.invoke(user_describe_prompt).content\n",
    "\n",
    "    return \"No user found with that name.\"\n",
    "\n",
    "\n",
    "find_user_tool = Tool(\n",
    "    name=\"find_user_tool\",\n",
    "    func=find_user_details,\n",
    "    description=\"A tool that finds user details by name.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e676f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [hello_tool, find_user_tool]\n",
    "llm = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dec83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c10581eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> dict:\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "684841c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c1ab289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5dff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = [\n",
    "    \"Hello, my name is Alice.\",\n",
    "    \"Can you find a user with name Clementine Bauch?\",\n",
    "    \"Can you find a user with name Patricia Lebsack?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc24bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Alice.\n",
      "<think>\n",
      "Okay, let's see. The user introduced themselves as Alice. I need to respond appropriately. The available tools are hello_tool and find_user_tool. The hello_tool is for greeting, and find_user_tool is for finding user details by name.\n",
      "\n",
      "Since the user provided their name, maybe I should use the find_user_tool to get more information about Alice. But wait, the find_user_tool's parameter is __arg1, which is a string. The description says it finds user details by name, so I should pass \"Alice\" as the argument. However, the user hasn't mentioned anything about needing user details yet. They just said hello. \n",
      "\n",
      "Alternatively, maybe I should first use the hello_tool to greet them. But the hello_tool's description says it greets with a hello message, and the parameter is __arg1, which is a string. Maybe the parameter is for the name to include in the greeting. So if I use hello_tool with \"Alice\", it would say hello to her. \n",
      "\n",
      "Wait, the user already said their name, so perhaps the appropriate response is to greet them using the hello_tool. Let me check the functions again. The hello_tool's parameters require __arg1, which is a string. The description is empty, but maybe it's intended to pass the name. So I can call hello_tool with \"Alice\" as the argument. That makes sense as a response to their introduction. \n",
      "\n",
      "Alternatively, if the find_user_tool is meant to retrieve user details, but the user hasn't asked for that. So the best immediate response is to greet them. So I'll use the hello_tool with __arg1 set to \"Alice\".\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, the user wants a friendly greeting for Alice that's short and cheerful. Let me check the tools available. There's the hello_tool which greets the user with a hello message. The parameters require __arg1, which is a string. Since the user specified Alice, I should use the hello_tool and pass \"Alice\" as the argument. That should generate a greeting like \"Hello, Alice!\" which fits the requirement. I don't need the find_user_tool here because the task is just a greeting, not retrieving user details. So the correct tool call is hello_tool with __arg1 set to Alice.\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "Hello, Alice! 😊\n",
      "Can you find a user with name Clementine Bauch?\n",
      "<think>\n",
      "Okay, the user is asking if I can find a user named Clementine Bauch. Let me check the available tools. There's the find_user_tool which is supposed to find user details by name. The parameters require a string, so I should use that. I need to call the find_user_tool with the argument \"__arg1\" set to \"Clementine Bauch\". Let me make sure the JSON is correctly formatted with the name and arguments. Alright, that should do it.\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, let me tackle this query. The user wants me to describe Clementine Bauch with specific details. First, I need to check if any of the provided tools can help. The available functions are hello_tool and find_user_tool.\n",
      "\n",
      "The hello_tool just greets the user, which doesn't fit here. The find_user_tool is supposed to find user details by name. Even though the description says it finds details by name, the parameters require a string argument. The user provided Clementine Bauch's name, email, address, and company. But the function's parameters only take a single string. Maybe the function can retrieve the details based on the name, but the example given in the function's parameters is empty. \n",
      "\n",
      "Wait, the user's example says to structure the response as \"User name is ABC with email XYZ, lives in city EFG and works in company HIJ.\" So maybe the find_user_tool can fetch the necessary info when given the name. Let me try using find_user_tool with the name Clementine Bauch. The function might return the details, and then I can format them into the required sentence. Since the parameters only take a single string, I'll pass the name as the argument. Then, once I get the data, I can construct the introduction as specified. I'll proceed with calling find_user_tool with \"__arg1\" as \"Clementine Bauch\".\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, let's see. The user wants me to describe Clementine Bauch with the given details. The example they provided is a brief intro, so I need to keep it concise.\n",
      "\n",
      "First, the name is Clementine Bauch. The email is Nathan@yesenia.net. Wait, the email is associated with Nathan? Or is that a typo? The user mentioned \"Clementine Bauch, Email: Nathan@yesenia.net\". Maybe it's a mistake, but I should follow the data as given. Maybe Nathan is the first name? Or perhaps it's a mix-up. But the user provided that email under Clementine's name, so I'll include it as is.\n",
      "\n",
      "Next, the address: Lives in McKenziehaven at Suite 847. So the city is McKenziehaven, and the suite number is part of the address. The example says \"lives in the city EFG\", so I should mention McKenziehaven as the city. The suite might be part of the address but maybe not necessary. Wait, the example doesn't include suite numbers, so perhaps I should just mention the city. But the user included the suite, so maybe I should include it. Let me check the example again. The example says \"lives in the city EFG\" so maybe the suite is part of the address but not the city. So I'll say \"lives in McKenziehaven, Suite 847.\"\n",
      "\n",
      "Then, works in Romaguera-Jacobson. The example says \"works in the company HIJ\", so that's straightforward. So putting it all together: Clementine Bauch has the email Nathan@yesenia.net, lives in McKenziehaven, Suite 847, and works in Romaguera-Jacobson. Wait, but the email is Nathan@yesenia.net. Maybe the user intended that email to be associated with Nathan, but the name is Clementine. Maybe there's an error here. But since the user provided that data, I should include it as is. So the final intro would be: \"Clementine Bauch has the email Nathan@yesenia.net, lives in McKenziehaven, Suite 847, and works in Romaguera-Jacobson.\" But the example uses \"with email XYZ\", so I should follow that structure. So the answer should be concise, matching the example format.\n",
      "</think>\n",
      "\n",
      "Clementine Bauch has the email Nathan@yesenia.net, lives in McKenziehaven, Suite 847, and works in Romaguera-Jacobson.\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "Clementine Bauch has the email Nathan@yesenia.net, lives in McKenziehaven, Suite 847, and works in Romaguera-Jacobson.\n",
      "Can you find a user with name Patricia Lebsack?\n",
      "<think>\n",
      "Okay, the user is asking to find a user named Patricia Lebsack. Let me check the available tools. There's the find_user_tool which takes a name as a parameter. I need to call that function with the name Patricia Lebsack. The parameters require __arg1, so I'll structure the argument accordingly. Let me make sure the JSON is correctly formatted with the name in the __arg1 field.\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, let's see. The user wants me to describe Patricia Lebsack with the given details. The example they provided is a brief intro, so I need to follow that structure.\n",
      "\n",
      "First, the name is Patricia Lebsack. The email is Julianne.OConner@kory.org. Wait, the email is listed under Patricia, so that's her email. Then she lives in South Elvis at Apt. 692. Her workplace is Robel-Corkery. \n",
      "\n",
      "The example says \"user name is ABC with email XYZ, lives in the city EFG and works in the company HIJ.\" So I need to structure it similarly. Let me check the parameters. The functions provided are hello_tool and find_user_tool. The find_user_tool takes a parameter __arg1, which is a string. But the user's query is about describing a user, so maybe the find_user_tool is used to get details. However, the user already provided all the details, so maybe I don't need to call a function here. Wait, but the instructions say to call one or more functions. Wait, the user might expect me to use the find_user_tool to retrieve the user's info. But since the user already gave all the details, maybe the function is not necessary. But the system message says to call functions if needed. Wait, the example given by the user is just an example of how to structure the response, not necessarily to call a function. Let me re-read the user's query.\n",
      "\n",
      "The user says: \"Describe the user with details Patricia Lebsack... Tell as if you are giving a brief introduction...\" So they want me to generate the description. But the tools available are hello_tool and find_user_tool. The find_user_tool's description says it finds user details by name. So maybe I should call find_user_tool with the name Patricia Lebsack to get the details. But the user already provided all the details, so perhaps the function is not needed. However, the user might have intended for me to use the function to fetch the data. But since the data is already given, maybe I can proceed to create the response directly. However, the system prompt says to call the functions if needed. Wait, the user's query is to describe the user, so maybe the function is not needed. But the tools are provided, so perhaps I should use find_user_tool. Let me check the parameters again. The find_user_tool requires __arg1, which is a string. The description says it finds user details by name. So if I call find_user_tool with \"Patricia Lebsack\", it might return the details. But the user already provided the details. However, maybe the function is a mock and the response is generated based on the provided data. Alternatively, maybe the user expects me to use the function to get the info. But since the info is already given, perhaps the correct approach is to use the function to retrieve it. But the user is not asking to find the user, but to describe them. So perhaps the correct approach is to generate the response directly. However, the system message says to call the functions if needed. Since the user provided all the details, maybe the function isn't needed. But the example given by the user is just an example of the format. Therefore, I should structure the response as per the example, using the provided details. So the final response would be: \"The user name is Patricia Lebsack with email Julianne.OConner@kory.org, lives in South Elvis and works in Robel-Corkery.\" But I need to make sure to include the apartment number. Wait, the user said \"Lives in South Elvis at Apt. 692.\" So the city is South Elvis, and the apartment is 692. The example says \"lives in the city EFG\", so maybe the city is South Elvis, and the apartment is part of the address. So the response would be: \"The user name is Patricia Lebsack with email Julianne.OConner@kory.org, lives in South Elvis at Apt. 692 and works in Robel-Corkery.\" But the example's structure is to mention the city and company. So maybe the apartment is part of the address, but the example's structure is to mention the city. So the response should follow the example's structure, which is to mention the city. Therefore, the apartment number is part of the address but perhaps not needed in the brief intro. Wait, the user's example says \"lives in the city EFG\" so the city is EFG. In the user's case, the city is South Elvis. So the response would be: \"The user name is Patricia Lebsack with email Julianne.OConner@kory.org, lives in South Elvis and works in Robel-Corkery.\" The apartment number is part of the address but maybe not necessary for the brief intro. But the user included it in their query, so maybe it's better to include it. However, the example doesn't include apartment numbers. Hmm. The user's instruction says to keep it short and concise. So perhaps the apartment is not needed. Therefore, the final response is as per the example, with the city and company. So the answer is: \"The user name is Patricia Lebsack with email Julianne.OConner@kory.org, lives in South Elvis and works in Robel-Corkery.\"\n",
      "</think>\n",
      "\n",
      "The user name is Patricia Lebsack with email Julianne.OConner@kory.org, lives in South Elvis and works in Robel-Corkery.\n",
      "<think>\n",
      "Okay, let me process this. The user asked to describe Patricia Lebsack, and I generated a response based on the provided details. But wait, the tools available include find_user_tool, which is supposed to find user details by name. The user's initial query was to find a user with that name, so maybe I should have called the find_user_tool first to get the details. However, the user already provided all the necessary information, so perhaps the function call wasn't needed. But according to the system message, I should call functions if needed. Let me check again.\n",
      "\n",
      "The user's original query was \"Can you find a user with name Patricia Lebsack?\" So the intent was to find the user, which would require using the find_user_tool. But in the response, I directly provided the details without calling the function. That might be incorrect. The correct approach would be to call find_user_tool with the name \"Patricia Lebsack\" to retrieve the details, then use those details to form the response. However, since the user already included all the details in their query, maybe the function call isn't necessary. But the system instructions say to use the tools when needed. So perhaps I should have called the function first. But in the previous response, I didn't do that. Hmm, this is a bit confusing. Maybe the user provided the details as part of the query, so the function isn't needed. But the initial response didn't use the tool. I think the correct approach is to call the find_user_tool to get the details, then present them. However, since the user already gave the details, maybe the function isn't needed. I'm a bit conflicted here. Let me proceed with the initial response since the user provided all the info.\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, let's see. The user wants me to describe Patricia Lebsack with the given details. First, I need to check if the tools provided can help here. The available functions are hello_tool and find_user_tool. The find_user_tool is supposed to find user details by name. But the parameters require __arg1, which is a string. The user provided the name Patricia Lebsack, so maybe I should call find_user_tool with that name. However, the example given in the query shows a structure where the email, city, and company are included. Wait, the tools might not have all the data. The find_user_tool's description says it finds user details by name, but the parameters only have __arg1 as a string. Maybe the function is supposed to return the user's details, but the parameters don't include the email or address. Hmm, maybe the function is a placeholder and the actual data is provided in the query. Since the user already provided all the details, perhaps I don't need to call any function. The task is to create a brief introduction using the given info. The example mentions the format: name, email, city, company. So I should structure the response accordingly. Let me check the user's query again. They specified to describe the user with the details provided, so maybe the tools aren't necessary here. The functions might not be able to retrieve the email, city, or company info. Therefore, I should proceed to create the introduction directly without using the tools. The answer should be concise, mentioning the name, email, city, and company. Let me put that together.\n",
      "</think>\n",
      "\n",
      "The user Patricia Lebsack has the email Julianne.OConner@kory.org, lives in South Elvis at Apt. 692, and works in Robel-Corkery.\n",
      "<think>\n",
      "Okay, let me process this. The user asked to describe Patricia Lebsack, and I generated a response based on the provided details. But wait, the tools available include find_user_tool, which is supposed to find user details by name. The user's initial query was to find a user with that name, so maybe I should have called the find_user_tool first to get the details. However, the user already provided all the necessary information, so perhaps the function call wasn't needed. But according to the system message, I should call functions if needed. Let me check again.\n",
      "\n",
      "The user's original query was \"Can you find a user with name Patricia Lebsack?\" So the intent was to find the user, which would require using the find_user_tool. But in the response, I directly provided the details without calling the function. That might be incorrect. The correct approach would be to call find_user_tool with the name \"Patricia Lebsack\" to retrieve the details, then use those details to form the response. However, since the user already included all the details in their query, maybe the function call isn't necessary. But the system instructions say to use the tools when needed. So perhaps I should have called the function first. But in the previous response, I didn't do that. Hmm, this is a bit confusing. Maybe the user provided the details as part of the query, so the function isn't needed. But the initial response didn't use the tool. I think the correct approach is to call the find_user_tool to get the details, then present them. However, since the user already gave the details, maybe the function isn't needed. I'm a bit conflicted here. Let me proceed with the initial response since the user provided all the info.\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:581\u001b[39m, in \u001b[36mget_executor_for_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextThreadPoolExecutor(\n\u001b[32m    579\u001b[39m     max_workers=config.get(\u001b[33m\"\u001b[39m\u001b[33mmax_concurrency\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    580\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m executor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/prebuilt/tool_node.py:238\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     outputs = [\n\u001b[32m    239\u001b[39m         *executor.map(\u001b[38;5;28mself\u001b[39m._run_one, tool_calls, input_types, config_list)\n\u001b[32m    240\u001b[39m     ]\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# preserve existing behavior for non-command tool outputs for backwards\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/threading.py:320\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m user_input \u001b[38;5;129;01min\u001b[39;00m user_inputs:\n\u001b[32m      2\u001b[39m     events = graph.stream({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, user_input)]}, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2024\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2018\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2019\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2020\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2021\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2022\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2023\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2031\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:230\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    228\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:546\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m config = patch_config(\n\u001b[32m    543\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    544\u001b[39m )\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    548\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:310\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langgraph/prebuilt/tool_node.py:237\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    235\u001b[39m config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    236\u001b[39m input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_executor_for_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# preserve existing behavior for non-command tool outputs for backwards\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tutorials/ai-experiments/02-agentic-langgraph-solution/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:578\u001b[39m, in \u001b[36mget_executor_for_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get an executor for a config.\u001b[39;00m\n\u001b[32m    570\u001b[39m \n\u001b[32m    571\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    575\u001b[39m \u001b[33;03m    Generator[Executor, None, None]: The executor.\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    577\u001b[39m config = config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mContextThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_concurrency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/threading.py:1112\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/threading.py:1132\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1133\u001b[39m         lock.release()\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "    events = graph.stream({\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\")\n",
    "\n",
    "    for event in events:\n",
    "        print(event[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
