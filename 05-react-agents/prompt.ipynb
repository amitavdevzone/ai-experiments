{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fe2974",
   "metadata": {},
   "source": [
    "# Understanding Prompts from Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b842db",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langgraph-supervisor langchain-openai python-dotenv arize-phoenix-otel openinference-instrumentation-langchain arize-phoenix-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88ab6e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "from phoenix.client import Client\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"http://localhost:6006\"\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "# configure the Phoenix tracer\n",
    "tracer_provider = register(\n",
    "    project_name=\"default\",  # Default is 'default'\n",
    "    auto_instrument=True,  # Auto-instrument your app based on installed OI dependencies\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=OPENAI_MODEL,\n",
    "    api_key=OPENAI_KEY,\n",
    ")\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a1cc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = client.prompts.get(prompt_version_id=\"UHJvbXB0VmVyc2lvbjo5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "91bcec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_provider': 'OPENAI', 'model_name': 'gpt-4o', 'template': {'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': \"You are a chatbot and you need to answer questions by user on Areize Phoneix project.\\n\\nBefore answering the question, you should greet the user. \\nHere are a few examples of greeting:\\n- Hey, that's a great question\\n- Wow, that's a nice one\\n\\nIMPORTANT: Answer to questions based on the knowledge you have in your context. Do not answer outside that and do not make up things.\"}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Phoenix is an open-source observability tool designed for experimentation, evaluation, and troubleshooting of AI and LLM applications. It allows AI engineers and data scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\\n\\nPhoenix is built by Arize AI, the company behind the industry-leading AI observability platform, and a set of core contributors.\\n\\n{{question}}'}]}], 'type': 'chat'}, 'template_type': 'CHAT', 'template_format': 'MUSTACHE', 'invocation_parameters': {'type': 'openai', 'openai': {'temperature': 1.0, 'top_p': 1.0}}, 'description': ''}\n"
     ]
    }
   ],
   "source": [
    "print(prompt._dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20755b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = prompt.format(\n",
    "    variables={\n",
    "        \"question\": \"What Arize Phoenix is used for?\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d1105f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LangChain messages\n",
    "messages = []\n",
    "for msg in formatted_prompt.messages:\n",
    "    if msg[\"role\"] == \"system\":\n",
    "        messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "    elif msg[\"role\"] == \"user\":\n",
    "        messages.append(HumanMessage(content=msg[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "609db841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Messages: [SystemMessage(content=\"You are a chatbot and you need to answer questions by user on Areize Phoneix project.\\n\\nBefore answering the question, you should greet the user. \\nHere are a few examples of greeting:\\n- Hey, that's a great question\\n- Wow, that's a nice one\\n\\nIMPORTANT: Answer to questions based on the knowledge you have in your context. Do not answer outside that and do not make up things.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Phoenix is an open-source observability tool designed for experimentation, evaluation, and troubleshooting of AI and LLM applications. It allows AI engineers and data scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\\n\\nPhoenix is built by Arize AI, the company behind the industry-leading AI observability platform, and a set of core contributors.\\n\\nWhat Arize Phoenix is used for?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(\"Formatted Messages:\", messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "af46ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96630695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      " Hey, that's a great question! Arize Phoenix is used for experimentation, evaluation, and troubleshooting of AI and LLM applications. It helps AI engineers and data scientists visualize their data, evaluate performance, identify issues, and export data to improve their models and processes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \\n\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
